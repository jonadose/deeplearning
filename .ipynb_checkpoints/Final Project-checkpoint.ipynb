{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project Group 4 \n",
    "Lorenzo, Brian, Mantas, Jona "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pillow\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import layers \n",
    "from tensorflow.keras import models \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the train folder\n",
    "original_train = 'C:/Users/jonad/deeplearning/dataset'\n",
    " \n",
    "filenames = os.listdir(original_train)\n",
    "categories = []\n",
    "for filename in filenames:\n",
    "    category = filename.split('.')[0]\n",
    "    if category == 'cat':\n",
    "        categories.append('0')\n",
    "    else:\n",
    "        categories.append('1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cat.0.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cat.1.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cat.10.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cat.100.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cat.1000.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>dog.995.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>dog.996.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>dog.997.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>dog.998.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>dog.999.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename label\n",
       "0        cat.0.jpg     0\n",
       "1        cat.1.jpg     0\n",
       "2       cat.10.jpg     0\n",
       "3      cat.100.jpg     0\n",
       "4     cat.1000.jpg     0\n",
       "...            ...   ...\n",
       "2995   dog.995.jpg     1\n",
       "2996   dog.996.jpg     1\n",
       "2997   dog.997.jpg     1\n",
       "2998   dog.998.jpg     1\n",
       "2999   dog.999.jpg     1\n",
       "\n",
       "[3000 rows x 2 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'filename':filenames,'label':categories})\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into train and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2761</th>\n",
       "      <td>dog.784.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>cat.1108.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>dog.1275.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2286</th>\n",
       "      <td>dog.356.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>dog.230.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>dog.1121.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>cat.634.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1130</th>\n",
       "      <td>cat.666.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1294</th>\n",
       "      <td>cat.813.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>cat.422.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2010 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          filename label\n",
       "2761   dog.784.jpg     1\n",
       "123   cat.1108.jpg     0\n",
       "1808  dog.1275.jpg     1\n",
       "2286   dog.356.jpg     1\n",
       "2147   dog.230.jpg     1\n",
       "...            ...   ...\n",
       "1638  dog.1121.jpg     1\n",
       "1095   cat.634.jpg     0\n",
       "1130   cat.666.jpg     0\n",
       "1294   cat.813.jpg     0\n",
       "860    cat.422.jpg     0\n",
       "\n",
       "[2010 rows x 2 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, validate_df = train_test_split(data, test_size=0.33, random_state=42)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11f00be8910>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df['label'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Data Generator \n",
    "for rescaling the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rescaler = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### flow_from_dataframe from the Data\n",
    "this creates a DataFrameIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2010 validated image filenames belonging to 2 classes.\n",
      "Found 990 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_mod = Rescaler.flow_from_dataframe(train_df, directory=original_train, \n",
    "x_col='filename', \n",
    "y_col='label',\n",
    "target_size=(128, 128), \n",
    "color_mode='rgb',\n",
    "class_mode='binary', \n",
    "batch_size=32, \n",
    ")\n",
    "\n",
    "val_data_mod = Rescaler.flow_from_dataframe(validate_df, directory=original_train, \n",
    "x_col='filename', \n",
    "y_col='label',\n",
    "target_size=(128, 128), \n",
    "color_mode='rgb',\n",
    "class_mode='binary', \n",
    "batch_size=32, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Builidng the model\n",
    "to begin with we started with the same CNN used in exercise 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_24 (Conv2D)           (None, 126, 126, 28)      784       \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 124, 124, 28)      7084      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling (None, 62, 62, 28)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 60, 60, 64)        16192     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 28, 28, 64)        36928     \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 50176)             0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                3211328   \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,272,381\n",
      "Trainable params: 3,272,381\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Creating a Sequential Model and adding the layers\n",
    "input_shape = (128,128, 3)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(Conv2D(28, kernel_size=(3,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu')) #test1 \n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(64, activation='relu'))# changed from 128 to 64\n",
    "#model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2010"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "990"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0720 - accuracy: 0.9766WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 198 batches). You may need to use the repeat() function when building your dataset.\n",
      "63/63 [==============================] - 43s 690ms/step - loss: 0.0720 - accuracy: 0.9766 - val_loss: 2.2762 - val_accuracy: 0.6172\n",
      "Epoch 2/10\n",
      "63/63 [==============================] - 37s 590ms/step - loss: 0.0414 - accuracy: 0.9881\n",
      "Epoch 3/10\n",
      "63/63 [==============================] - 37s 595ms/step - loss: 0.0878 - accuracy: 0.9771\n",
      "Epoch 4/10\n",
      "63/63 [==============================] - 38s 604ms/step - loss: 0.0138 - accuracy: 0.9965\n",
      "Epoch 5/10\n",
      "63/63 [==============================] - 39s 612ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 6/10\n",
      "63/63 [==============================] - 39s 620ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 7/10\n",
      "63/63 [==============================] - 39s 620ms/step - loss: 8.1586e-04 - accuracy: 1.0000\n",
      "Epoch 8/10\n",
      "63/63 [==============================] - 39s 620ms/step - loss: 6.3203e-04 - accuracy: 1.0000\n",
      "Epoch 9/10\n",
      "63/63 [==============================] - 41s 645ms/step - loss: 5.2324e-04 - accuracy: 1.0000\n",
      "Epoch 10/10\n",
      "63/63 [==============================] - 39s 619ms/step - loss: 4.7087e-04 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', \n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Parameters: \n",
    "epochs=10 \n",
    "batch_size=5\n",
    "total_train= train_df.shape[0]\n",
    "total_validate=validate_df.shape[0]\n",
    "validation_steps=(total_validate//batch_size)\n",
    "steps_per_epoch=(total_train//batch_size)\n",
    "\n",
    "\n",
    "history = model.fit(train_data_mod, epochs=epochs,\n",
    "                    validation_data=val_data_mod,\n",
    "                    validation_steps=validation_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 5s 150ms/step - loss: 1.4123 - accuracy: 0.6071\n",
      "\n",
      " metrics:  ['loss', 'accuracy']\n",
      "\n",
      " evaluation results:  [1.4123198986053467, 0.6070706844329834]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (10,) and (1,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-f199a5563a57>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# Plot properties\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'bo'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Training loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_loss_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'b'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Validation loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Training and validation loss'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Epochs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2759\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mdocstring\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2760\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscalex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2761\u001b[1;33m     return gca().plot(\n\u001b[0m\u001b[0;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m   2763\u001b[0m         is not None else {}), **kwargs)\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mplot\u001b[1;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1645\u001b[0m         \"\"\"\n\u001b[0;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1647\u001b[1;33m         \u001b[0mlines\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1648\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[1;34m(self, tup, kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[0;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (10,) and (1,)"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAARf0lEQVR4nO3df4xd6X3X8fdnvF3RSUv6Y6ct2OsZU9yGBSVtuWxbWmhoSHFKWzeiqN4OpYRKIyO2FIQg21oqf0SWQCBUJLZdjcKSSr2KFSVLY8o22ypAU1FaeZxu0/VuN1jO2jt1YJ0EGpJBWpz98se9xncm8+OOfWfOncfvl2Sd+zzn0blfHdmf+/i5556TqkKSdPDNdF2AJGkyDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEaMFehJTiR5McnlJI9tsv/1Sf59kt9NcinJOyZfqiRpO9npOvQkh4CPA28FVoELwCNV9fzImJ8GXl9V70wyB7wIfF1VvbpnlUuS1hlnhv4wcLmqrgwD+hxwcsOYAr48SYAvAz4D3JxopZKkbd03xpjDwMsj7VXgWzeM+dfAeeA68OXAD1fVa9sd9IEHHqiFhYXxK5UkcfHixU9V1dxm+8YJ9GzSt3Gd5q8AzwLfDXw98GtJfqOqPrvuQMkSsARw9OhRVlZWxnh7SdItSa5utW+cJZdV4MGR9hEGM/FR7wCeqoHLwCeAN2w8UFUtV1Wvqnpzc5t+wEiS7tA4gX4BOJ7kWJL7gVMMlldGXQPeApDka4FvBK5MslBJ0vZ2XHKpqptJHgWeAQ4BT1bVpSSnh/ufAN4FvCfJ7zFYonlnVX1qD+uWJG0wzho6VfU08PSGvidGXl8HvmeypUmSdsNfikpSIw5UoPf7sLAAMzODbb/fdUWSND3GWnKZBv0+LC3B2tqgffXqoA2wuNhdXZI0LQ7MDP3Mmdthfsva2qBfknSAAv3atd31S9K95sAE+tGju+uXpHvNgQn0s2dhdnZ93+zsoF+SdIACfXERlpdhfh6SwXZ52S9EJemWA3OVCwzC2wCXpM0dmBm6JGl7BrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1Ijxgr0JCeSvJjkcpLHNtn/j5I8O/zzXJIvJPmqyZcrSdrKjoGe5BDwOPA24CHgkSQPjY6pqn9eVd9UVd8E/BTw61X1mb0oWJK0uXFm6A8Dl6vqSlW9CpwDTm4z/hHgvZMoTpI0vnEC/TDw8kh7ddj3RZLMAieAD9x9aToo+n1YWICZmcG23++6IuneNM4j6LJJX20x9vuB/7LVckuSJWAJ4OjRo2MVqOnW78PSEqytDdpXrw7a4OMCpf02zgx9FXhwpH0EuL7F2FNss9xSVctV1auq3tzc3PhVThlnpLedOXM7zG9ZWxv0S9pf4wT6BeB4kmNJ7mcQ2uc3DkryeuC7gA9OtsTpcmtGevUqVN2ekXYR6tPwwXLt2u7699I0nA+pSzsGelXdBB4FngFeAN5XVZeSnE5yemTo24FfrarP702p02FaZqTT8sGy1crZfq+oTcv5kLqUqq2Ww/dWr9erlZWVTt77bszMDAJjowRee23/6lhYGITWRvPz8NJL+1fHxjV0gNlZWF7e3zX0aTkf0l5LcrGqepvt85eiuzQtM9JpWepYXByE9/z84ENtfn7/wxym53xIXTLQd+ns2cEMdNTs7KB/P03LBwsMwvullwb/Q3nppW6ubpmm8yF1xUDfpWmZkU7LB8u08HxIBvodmYYZ6bR8sEwLz4fkl6KSdKD4pagk3QMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjo0oR510d1ZZwHXEgakw/8UJecoUsTNC23V9a9yUCXJsi7PqpLBro0Qd71UV0y0KUJ8q6P6pKBLk2Qd31Ul7zKRZqwxUUDXN1whi5JjTDQJakRBrokNcJAl6RGjBXoSU4keTHJ5SSPbTHmzUmeTXIpya9PtkxJ0k52vMolySHgceCtwCpwIcn5qnp+ZMxXAD8HnKiqa0m+Zq8KliRtbpwZ+sPA5aq6UlWvAueAkxvG/AjwVFVdA6iqVyZbpiRpJ+ME+mHg5ZH26rBv1DcAX5nkPye5mORvTqpASdJ4xvlhUTbpq02O82eBtwBfCvzXJL9VVR9fd6BkCVgCOOrNLSRposaZoa8CD460jwDXNxnzoar6fFV9CvgI8KaNB6qq5arqVVVvbm7uTmuWJG1inEC/ABxPcizJ/cAp4PyGMR8E/kKS+5LMAt8KvDDZUiVJ29lxyaWqbiZ5FHgGOAQ8WVWXkpwe7n+iql5I8iHgY8BrwLur6rm9LFyStF6qNi6H749er1crKyudvLckHVRJLlZVb7N9/lJUkhphoEtSIwx0qUH9PiwswMzMYNvvd12R9oMPuJAa0+/D0hKsrQ3aV68O2uCDN1rnDF1qzJkzt8P8lrW1Qb/aZqBLjbl2bXf9aoeBLjVmq7tqeLeN9hnoUmPOnoXZ2fV9s7ODfrXNQJcas7gIy8swPw/JYLu87Bei9wKvcpEatLhogN+LnKFLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1YqxAT3IiyYtJLid5bJP9b07yh0meHf75mcmXKknazo63z01yCHgceCuwClxIcr6qnt8w9Deq6vv2oEZJ0hjGmaE/DFyuqitV9SpwDji5t2VJknZrnEA/DLw80l4d9m307Ul+N8mvJPnTE6lOkjS2cZ5YlE36akP7o8B8VX0uyfcCvwQc/6IDJUvAEsBRn1grSRM1zgx9FXhwpH0EuD46oKo+W1WfG75+GviSJA9sPFBVLVdVr6p6c3Nzd1G2JGmjcQL9AnA8ybEk9wOngPOjA5J8XZIMXz88PO6nJ12sJGlrOy65VNXNJI8CzwCHgCer6lKS08P9TwA/BPydJDeB/wOcqqqNyzKSpD2UrnK31+vVyspKJ+8tSQdVkotV1dtsn78UlaRGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA13Snun3YWEBZmYG236/64raNs790CVp1/p9WFqCtbVB++rVQRtgcbG7ulrmDF3Snjhz5naY37K2NujX3jDQJe2Ja9d216+7Z6BL2hNbPWXSp0/uHQNd0p44exZmZ9f3zc4O+rU3DHRJe2JxEZaXYX4eksF2edkvRPeSV7lI2jOLiwb4fnKGLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhoxVqAnOZHkxSSXkzy2zbg/l+QLSX5ociVKksaxY6AnOQQ8DrwNeAh4JMlDW4z7Z8Azky5SkrSzcWboDwOXq+pKVb0KnANObjLuJ4APAK9MsD5J0pjGCfTDwMsj7dVh3/+X5DDwduCJ7Q6UZCnJSpKVGzdu7LZWSdI2xgn0bNJXG9o/C7yzqr6w3YGqarmqelXVm5ubG7dGSdIYxrmXyyrw4Ej7CHB9w5gecC4JwAPA9ya5WVW/NJEqJUk7GifQLwDHkxwD/gA4BfzI6ICqOnbrdZL3AL9smEvS/tox0KvqZpJHGVy9cgh4sqouJTk93L/turkkaX+MdfvcqnoaeHpD36ZBXlV/6+7LkiTtlr8UlaRGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEYY6JLUCANdkhphoEtSIwx0SWqEgS5JjTDQJakRYwV6khNJXkxyOcljm+w/meRjSZ5NspLkOydfqiRpO/ftNCDJIeBx4K3AKnAhyfmqen5k2IeB81VVSd4IvA94w14ULEna3Dgz9IeBy1V1papeBc4BJ0cHVNXnqqqGzdcBhSRpX40T6IeBl0faq8O+dZK8PcnvA/8B+NuTKU+SNK5xAj2b9H3RDLyq/l1VvQH4QeBdmx4oWRqusa/cuHFjd5VKkrY1TqCvAg+OtI8A17caXFUfAb4+yQOb7Fuuql5V9ebm5nZdrCTdiX4fFhZgZmaw7fe7rmhvjBPoF4DjSY4luR84BZwfHZDkTybJ8PW3APcDn550sZK0W/0+LC3B1atQNdguLbUZ6jsGelXdBB4FngFeAN5XVZeSnE5yejjsrwHPJXmWwRUxPzzyJakkdebMGVhbW9+3tjbob026yt1er1crKyudvLeke8fMzGBmvlECr722//XcrSQXq6q32T5/KSqpaUeP7q7/IDPQJTXt7FmYnV3fNzs76G+NgS6paYuLsLwM8/ODZZb5+UF7cbHryiZvx5/+S9JBt7jYZoBv5AxdkhphoEtSIwx0SWqEgS5JjTDQJakRBrokNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSY0w0CWpEQa6JDXCQJekRhjoktQIA12SGmGgS1IjDHRJasRYgZ7kRJIXk1xO8tgm+xeTfGz45zeTvGnypUqStrNjoCc5BDwOvA14CHgkyUMbhn0C+K6qeiPwLmB50oVKkrY3zgz9YeByVV2pqleBc8DJ0QFV9ZtV9T+Hzd8Cjky2TEnSTsYJ9MPAyyPt1WHfVn4c+JW7KUqStHv3jTEmm/TVpgOTv8Qg0L9zi/1LwBLA0aNHxyxRkjSOcWboq8CDI+0jwPWNg5K8EXg3cLKqPr3Zgapquap6VdWbm5u7k3olSVsYJ9AvAMeTHEtyP3AKOD86IMlR4CngR6vq45MvU5K0kx2XXKrqZpJHgWeAQ8CTVXUpyenh/ieAnwG+Gvi5JAA3q6q3d2VLkjZK1abL4Xuu1+vVyspKJ+8tSQdVkotbTZj9pagkNcJAl6RGGOiS1AgDXZIaYaBLUiMMdElqhIEuSfuk34eFBZiZGWz7/ckef5x7uUiS7lK/D0tLsLY2aF+9OmgDLC5O5j2coUvSPjhz5naY37K2NuifFANdkvbBtWu7678TBrok7YOt7hg+yTuJG+iStA/OnoXZ2fV9s7OD/kkx0CVpHywuwvIyzM9DMtguL0/uC1HwKhdJ2jeLi5MN8I2coUtSIwx0SWqEgS5JjTDQJakRBrokNaKzZ4omuQFc7eTNJ+cB4FNdFzFFPB/reT5u81ysdzfnY76q5jbb0VmgtyDJylYPa70XeT7W83zc5rlYb6/Oh0suktQIA12SGmGg353lrguYMp6P9Twft3ku1tuT8+EauiQ1whm6JDXCQL8DSR5M8p+SvJDkUpKf7LqmriU5lOR3kvxy17V0LclXJHl/kt8f/h359q5r6lKSfzD8d/Jckvcm+SNd17SfkjyZ5JUkz430fVWSX0vy34bbr5zEexnod+Ym8A+r6k8B3wb83SQPdVxT134SeKHrIqbEvwI+VFVvAN7EPXxekhwG/h7Qq6o/AxwCTnVb1b57D3BiQ99jwIer6jjw4WH7rhnod6CqPllVHx2+/t8M/sEe7raq7iQ5AvxV4N1d19K1JH8U+IvAvwGoqler6n91W1Xn7gO+NMl9wCxwveN69lVVfQT4zIbuk8AvDF//AvCDk3gvA/0uJVkAvhn47W4r6dTPAv8YeK3rQqbAnwBuAP92uAT17iSv67qorlTVHwD/ArgGfBL4w6r61W6rmgpfW1WfhMEEEfiaSRzUQL8LSb4M+ADw96vqs13X04Uk3we8UlUXu65lStwHfAvw81X1zcDnmdB/pw+i4drwSeAY8MeB1yX5G91W1S4D/Q4l+RIGYd6vqqe6rqdD3wH8QJKXgHPAdyf5xW5L6tQqsFpVt/7H9n4GAX+v+svAJ6rqRlX9X+Ap4M93XNM0+B9J/hjAcPvKJA5qoN+BJGGwRvpCVf3LruvpUlX9VFUdqaoFBl92/cequmdnYFX134GXk3zjsOstwPMdltS1a8C3JZkd/rt5C/fwl8QjzgM/Nnz9Y8AHJ3FQnyl6Z74D+FHg95I8O+z76ap6usOaND1+AugnuR+4Aryj43o6U1W/neT9wEcZXB32O9xjvxpN8l7gzcADSVaBfwL8U+B9SX6cwYfeX5/Ie/lLUUlqg0suktQIA12SGmGgS1IjDHRJaoSBLkmNMNAlqREGuiQ1wkCXpEb8P665449Qz+mTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "results = model.evaluate(val_data_mod, batch_size=32)\n",
    "print(\"\\n metrics: \", model.metrics_names)\n",
    "print(\"\\n evaluation results: \",results)\n",
    "\n",
    "\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(loss_values)+ 1)\n",
    "\n",
    "# Plot properties \n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
