{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 6 - Recurrent Neural Networks \n",
    "\n",
    "Today you will be taking another look at the IMDB movie review dataset.\n",
    "\n",
    "First, you must make a typical feed-forward network using the Functional API in Keras.\n",
    "\n",
    "Second, you must make a recurrent neural network using the Functional API. \n",
    "\n",
    "The choice of which kind of recurrent layers you want is up to you.\n",
    "\n",
    "\n",
    "Consider how you want your input data encoded.\n",
    "\n",
    "``from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np``\n",
    "\n",
    "``numwords = 10000\n",
    "maxlen = 500``\n",
    "\n",
    "``(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=numwords)``\n",
    "\n",
    "``x_train = pad_sequences(x_train, maxlen=maxlen)``\n",
    "``x_test = pad_sequences(x_test, maxlen=maxlen)``\n",
    "\n",
    "``y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)``\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Feedforward Functional API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow.keras as tfk\n",
    "import numpy as np\n",
    "\n",
    "numwords = 10000\n",
    "maxlen = 500\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = tfk.datasets.imdb.load_data(num_words=numwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoding the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"? big hair big boobs bad music and a giant safety pin these are the words to best describe this terrible movie i love cheesy horror movies and i've seen hundreds but this had got to be on of the worst ever made the plot is paper thin and ridiculous the acting is an abomination the script is completely laughable the best is the end showdown with the cop and how he worked out who the killer is it's just so damn terribly written the clothes are sickening and funny in equal ? the hair is big lots of boobs ? men wear those cut ? shirts that show off their ? sickening that men actually wore them and the music is just ? trash that plays over and over again in almost every scene there is trashy music boobs and ? taking away bodies and the gym still doesn't close for ? all joking aside this is a truly bad film whose only charm is to look back on the disaster that was the 80's and have a good old laugh at how bad everything was back then\""
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_review(X):\n",
    "\n",
    "    from tensorflow.keras.datasets import imdb\n",
    "\n",
    "    # Let's quickly decode a review\n",
    "    word_index = imdb.get_word_index()\n",
    "\n",
    "    reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "    decoded_review = ' '.join([reverse_word_index.get(i-3, '?') for i in X])\n",
    "\n",
    "    return decoded_review\n",
    "decode_review(train_data[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 0, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pad_sequences(x_train, maxlen=maxlen) \n",
    "test_data = pad_sequences(x_test, maxlen=maxlen)\n",
    "\n",
    "#train_labels = to_categorical(y_train)\n",
    "#test_labels = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode_review(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def multi_hot_sequences(sequences, dimension):\n",
    "    #Create an all-zero matrix of shape (len(sequences), dimension)\n",
    "    results = np.zeros((len(sequences), dimension))\n",
    "    for i, word_indices in enumerate(sequences):\n",
    "        results[i, word_indices] = 1.0  # set specific indices of results[i] to 1s\n",
    "    return results\n",
    "\n",
    "x_train = multi_hot_sequences(train_data, dimension=numwords)\n",
    "x_test = multi_hot_sequences(test_data, dimension=numwords)\n",
    "\n",
    "#splitting the train_data into train AND validation data\n",
    "#train_data, validation_data, train_labels, validation_labels = train_test_split(train_data, train_labels, test_size =0.33, random_state=42)\n",
    "\n",
    "# Decoding again after encoding \n",
    "decode_review(train_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the feedforward model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text (InputLayer)            [(None, 500)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_23 (Embedding)     (None, 500, 10000)        640000    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 500, 32)           320032    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 500, 32)           0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 500, 32)           1056      \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 500, 32)           1056      \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 500, 1)            33        \n",
      "=================================================================\n",
      "Total params: 962,177\n",
      "Trainable params: 962,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(maxlen,), dtype='int32', name='text')\n",
    "x = Embedding(64, numwords)(inputs)\n",
    "x = Dense(32, activation='relu', input_shape=(maxlen,))(x) # (x) concatenates the layer\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(32, activation='relu', kernel_regularizer='l1')(x)\n",
    "x = Dense(32, activation='softmax', kernel_regularizer='l1')(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model_ff = Model(inputs,outputs)\n",
    "model_ff.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_ff.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "#model_ff.fit(train_data, train_labels, batch_size=32, epochs=2, validation_data=(test_data, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the RNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "text (InputLayer)            [(None, 500)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_25 (Embedding)     (None, 500, 10000)        640000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_5 (SimpleRNN)     (None, 500, 32)           321056    \n",
      "_________________________________________________________________\n",
      "simple_rnn_6 (SimpleRNN)     (None, 500, 32)           2080      \n",
      "_________________________________________________________________\n",
      "simple_rnn_7 (SimpleRNN)     (None, 500, 32)           2080      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 500, 1)            33        \n",
      "=================================================================\n",
      "Total params: 965,249\n",
      "Trainable params: 965,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(maxlen,), dtype='int32', name='text')\n",
    "x = Embedding(64, numwords)(inputs)\n",
    "x= layers.SimpleRNN(32, return_sequences=True)(x)\n",
    "x= layers.SimpleRNN(32, return_sequences=True)(x)\n",
    "x= layers.SimpleRNN(32, return_sequences=True)(x)\n",
    "outputs= Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "model_rnn = Model(inputs, outputs)\n",
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_rnn.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "#model_rnn.fit(train_data, train_labels, batch_size=32, epochs=2, validation_data=(test_data, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
